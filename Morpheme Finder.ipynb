{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpheme Finder\n",
    "[TOC]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Define Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from requests import request, ConnectionError\n",
    "from json import loads\n",
    "\n",
    "word_dict = defaultdict(None)\n",
    "label_func = defaultdict(None)\n",
    "known_prefixes = set()\n",
    "known_suffixes = set()\n",
    "\n",
    "EVQR_AFFIX = '<evqr.affix>'\n",
    "PREFIX_AND_SUFFIX = '<prefix.and.suffix>'\n",
    "VOWEL = '<vowel>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('.env.json') as f:\n",
    "        ENV_VARIABLES = loads(f.read())\n",
    "        f.close()\n",
    "except FileNotFoundError:\n",
    "    ENV_VARIABLES = {'DATA_DIR': 'C:\\\\'}\n",
    "DATA_DIR = ENV_VARIABLES['DATA_DIR']\n",
    "FTP_DIR = 'http://m106.nthu.edu.tw/~s106062341/morpheme_finder_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Word:\n",
    "\n",
    "    @staticmethod\n",
    "    def create_synonym_postfix(word, delete=None, append=None):\n",
    "        return f'{word}{f\"--{delete}--\" if delete is not None else \"\"}{f\"++{append}++\" if append is not None else \"\"}'\n",
    "\n",
    "    @staticmethod\n",
    "    def create_synonym_prefix(word, delete=None, append=None):\n",
    "        return f'{f\"--{delete}--\" if delete is not None else \"\"}{f\"++{append}++\" if append is not None else \"\"}{word}'\n",
    "\n",
    "    @staticmethod\n",
    "    def letter_cmp(a, b):\n",
    "        divider = 0\n",
    "        for i, (letter_a, letter_b) in enumerate(zip(a, b)):\n",
    "            if letter_a != letter_b:\n",
    "                divider = i\n",
    "        return min(divider, len(a), len(b))\n",
    "\n",
    "    def __init__(self, text, affix_list):\n",
    "        self.text = text\n",
    "        self.affix_list = affix_list\n",
    "        self.synonym = defaultdict(None)\n",
    "        self.label = defaultdict(None)\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        return sum([c for c in self.synonym.values()])\n",
    "\n",
    "    def create_label(self, label_name, *args):\n",
    "        if label_name not in label_func:\n",
    "            return False\n",
    "        self.label[label_name] = label_func[label_name](self, *args)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Accessing\n",
    "### first provide a method to access files either in local storage or in FTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_file(filename: str, callback: classmethod) -> bool:\n",
    "    try:\n",
    "        with open(f'{DATA_DIR}{filename}', 'r') as f:\n",
    "            callback(f.read())\n",
    "            f.close()\n",
    "            return True\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            res = request('GET', f'{FTP_DIR}{filename}')\n",
    "            res.encoding = 'Big5'\n",
    "            callback(res.text)\n",
    "            return True\n",
    "        except ConnectionError:\n",
    "            print('HTTP connection failed')\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f'Load failed: {e}')\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "includes:\n",
    "1. *EVQR.word.and.affix.txt'*\n",
    "2. *prefixes.txt*\n",
    "3. *suffixes.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load done\n"
     ]
    }
   ],
   "source": [
    "def evqr_word_and_suffix_callback(content):\n",
    "    for line in content.split('\\n')[1:-1]:\n",
    "        word, *affix_list = line.replace('-', '').split(' ')[:-1]\n",
    "        word_dict[word] = (Word(word, affix_list))\n",
    "if get_file('EVQR.word.and.affix.txt', evqr_word_and_suffix_callback):\n",
    "    print('Load done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load prefixes & suffixes done\n"
     ]
    }
   ],
   "source": [
    "def prefix_callback(content):\n",
    "    for line in content.split('\\n')[1:-1]:\n",
    "        known_prefixes.update(filter(lambda x: len(x) > 0, line[:-1].strip().replace('-', '').split(', ')))\n",
    "\n",
    "def suffix_callback(content):\n",
    "    for line in content.split('\\n'):\n",
    "        known_suffixes.update(filter(lambda x: len(x) > 0, line[:-1].strip().replace('-', '').split(', ')))\n",
    "\n",
    "if get_file('prefixes.txt', prefix_callback) and get_file('suffixes.txt', suffix_callback):\n",
    "    print('Load prefixes & suffixes done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelize Word\n",
    "### Mapping Label Function\n",
    "because different label has its label function respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping done\n"
     ]
    }
   ],
   "source": [
    "def evqr_affix(word):\n",
    "    text = word.text\n",
    "    label = [0] * len(text)\n",
    "    pos = 0\n",
    "    for affix in word.affix_list:\n",
    "        if affix.lower() in text:\n",
    "            label[text.find(affix, pos)] = 1 if pos != 0 else 0\n",
    "            pos = text.find(affix, pos) + len(affix)\n",
    "        else:\n",
    "            k = Word.letter_cmp(text[pos:], affix)\n",
    "            if k > 1:\n",
    "                label[pos] = 1 if pos != 0 else 0\n",
    "                pos += 1\n",
    "\n",
    "    return [t for t in zip(text, label)]\n",
    "\n",
    "def vowel(word):\n",
    "    vowels = {\"a\", \"e\", \"i\", \"o\", \"u\"}\n",
    "    return [(letter, int(letter in vowels)) for letter in word.text]\n",
    "\n",
    "def prefix_and_suffix(word):\n",
    "    word_len = len(word.text)\n",
    "    label = [0] * word_len\n",
    "\n",
    "    for i in range(word_len):\n",
    "        pattern = word.text[:word_len - 1 - i]\n",
    "        if pattern in known_prefixes:\n",
    "            label[len(pattern)] = 1\n",
    "\n",
    "    for i in range(word_len):\n",
    "        pattern = word.text[i + 1:]\n",
    "        if pattern in known_suffixes:\n",
    "            label[i] = 2 if label[i] == 0 else 3\n",
    "\n",
    "    return [t for t in zip(word.text, label)]\n",
    "\n",
    "label_func[EVQR_AFFIX] = evqr_affix\n",
    "label_func[VOWEL] = vowel\n",
    "label_func[PREFIX_AND_SUFFIX] = prefix_and_suffix\n",
    "print('Mapping done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Label for each Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5237/5237 [00:00<00:00, 73924.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for word in tqdm(word_dict.values()):\n",
    "    if not word.create_label(EVQR_AFFIX):\n",
    "        print('Failed at label with EVQR.affix')\n",
    "    if not word.create_label(VOWEL):\n",
    "        print('Failed at label with Vowel')\n",
    "    if not word.create_label(PREFIX_AND_SUFFIX):\n",
    "        print('Failed at label with prefix & suffix')\n",
    "print('Label done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'labeled by EVQR.word.and.suffix: ignoble -> {word_dict[\"ignoble\"].label[EVQR_AFFIX]}')\n",
    "print(f'labeled by prefix & suffix     : demagog -> {word_dict[\"demagog\"].label[PREFIX_AND_SUFFIX]}')\n",
    "print(f'labeled by position of vowels  : amphibology -> {word_dict[\"amphibology\"].label[VOWEL]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepared_word = []\n",
    "for word in tqdm(word_dict.values()):\n",
    "    prepared_word.append(word.label[PREFIX_AND_SUFFIX])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_char_features(word, i):\n",
    "    features = [\n",
    "        'bias',\n",
    "        'char=' + word[i][0]\n",
    "    ]\n",
    "\n",
    "    if i >= 1:\n",
    "        features.extend([\n",
    "            'char-1=' + word[i-1][0],\n",
    "            'char-1:0=' + word[i-1][0] + word[i][0],\n",
    "        ])\n",
    "    else:\n",
    "        features.append(\"BOS\")\n",
    "\n",
    "    if i >= 2:\n",
    "        features.extend([\n",
    "            'char-2=' + word[i-2][0],\n",
    "            'char-2:0=' + word[i-2][0] + word[i-1][0] + word[i][0],\n",
    "            'char-2:-1=' + word[i-2][0] + word[i-1][0],\n",
    "        ])\n",
    "    return features\n",
    "\n",
    "\n",
    "def create_word_features(prepared_word):\n",
    "    return [create_char_features(prepared_word, i) for i in range(len(prepared_word))]\n",
    "\n",
    "\n",
    "def create_word_labels(prepared_word):\n",
    "    return [str(part[1]) for part in prepared_word]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}