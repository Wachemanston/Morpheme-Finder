{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpheme Finder\n",
    "[TOC]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Define Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from requests import request, ConnectionError\n",
    "from json import loads\n",
    "from random import sample\n",
    "from math import ceil\n",
    "import pycrfsuite\n",
    "\n",
    "word_dict = defaultdict(None)\n",
    "label_func = defaultdict(None)\n",
    "known_prefixes = set()\n",
    "known_suffixes = set()\n",
    "\n",
    "EVQR_AFFIX = '<evqr.affix>'\n",
    "PREFIX_AND_SUFFIX = '<prefix.and.suffix>'\n",
    "VOWEL = '<vowel>'\n",
    "\n",
    "CROSS_VALIDATION_FOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('.env.json') as f:\n",
    "        ENV_VARIABLES = loads(f.read())\n",
    "        f.close()\n",
    "except FileNotFoundError:\n",
    "    ENV_VARIABLES = {'DATA_DIR': 'C:\\\\'}\n",
    "DATA_DIR = ENV_VARIABLES['DATA_DIR']\n",
    "FTP_DIR = 'http://m106.nthu.edu.tw/~s106062341/morpheme_finder_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Word:\n",
    "\n",
    "    @staticmethod\n",
    "    def create_synonym_postfix(word, delete=None, append=None):\n",
    "        return f'{word}{f\"--{delete}--\" if delete is not None else \"\"}{f\"++{append}++\" if append is not None else \"\"}'\n",
    "\n",
    "    @staticmethod\n",
    "    def create_synonym_prefix(word, delete=None, append=None):\n",
    "        return f'{f\"--{delete}--\" if delete is not None else \"\"}{f\"++{append}++\" if append is not None else \"\"}{word}'\n",
    "\n",
    "    @staticmethod\n",
    "    def letter_cmp(a, b):\n",
    "        divider = 0\n",
    "        for i, (letter_a, letter_b) in enumerate(zip(a, b)):\n",
    "            if letter_a != letter_b:\n",
    "                divider = i\n",
    "        return min(divider, len(a), len(b))\n",
    "\n",
    "    def __init__(self, text, affix_list):\n",
    "        self.text = text\n",
    "        self.affix_list = affix_list\n",
    "        self.synonym = defaultdict(None)\n",
    "        self.label = defaultdict(None)\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        return sum([c for c in self.synonym.values()])\n",
    "\n",
    "    def create_label(self, label_name, *args):\n",
    "        if label_name not in label_func:\n",
    "            return False\n",
    "        self.label[label_name] = label_func[label_name](self, *args)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Accessing\n",
    "### first provide a method to access files either in local storage or in FTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_file(filename: str, callback: classmethod) -> bool:\n",
    "    try:\n",
    "        with open(f'{DATA_DIR}{filename}', 'r') as f:\n",
    "            callback(f.read())\n",
    "            f.close()\n",
    "            return True\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            res = request('GET', f'{FTP_DIR}{filename}')\n",
    "            res.encoding = 'Big5'\n",
    "            callback(res.text)\n",
    "            return True\n",
    "        except ConnectionError:\n",
    "            print('HTTP connection failed')\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f'Load failed: {e}')\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "includes:\n",
    "1. *EVQR.word.and.affix.txt'*\n",
    "2. *prefixes.txt*\n",
    "3. *suffixes.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load done\n"
     ]
    }
   ],
   "source": [
    "def evqr_word_and_suffix_callback(content):\n",
    "    for line in content.split('\\n')[1:-1]:\n",
    "        word, *affix_list = line.replace('-', '').split(' ')[:-1]\n",
    "        word_dict[word] = (Word(word, affix_list))\n",
    "if get_file('EVQR.word.and.affix.txt', evqr_word_and_suffix_callback):\n",
    "    print('Load done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load prefixes & suffixes done\n"
     ]
    }
   ],
   "source": [
    "def prefix_callback(content):\n",
    "    for line in content.split('\\n')[1:-1]:\n",
    "        known_prefixes.update(filter(lambda x: len(x) > 0, line[:-1].strip().replace('-', '').split(', ')))\n",
    "\n",
    "def suffix_callback(content):\n",
    "    for line in content.split('\\n'):\n",
    "        known_suffixes.update(filter(lambda x: len(x) > 0, line[:-1].strip().replace('-', '').split(', ')))\n",
    "\n",
    "if get_file('prefixes.txt', prefix_callback) and get_file('suffixes.txt', suffix_callback):\n",
    "    print('Load prefixes & suffixes done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelize Word\n",
    "### Mapping Label Function\n",
    "because different label has its label function respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping done\n"
     ]
    }
   ],
   "source": [
    "def evqr_affix(word):\n",
    "    text = word.text\n",
    "    label = [0] * len(text)\n",
    "    pos = 0\n",
    "    for affix in word.affix_list:\n",
    "        if affix.lower() in text:\n",
    "            label[text.find(affix, pos)] = 1 if pos != 0 else 0\n",
    "            pos = text.find(affix, pos) + len(affix)\n",
    "        else:\n",
    "            k = Word.letter_cmp(text[pos:], affix)\n",
    "            if k > 1:\n",
    "                label[pos] = 1 if pos != 0 else 0\n",
    "                pos += 1\n",
    "\n",
    "    return [t for t in zip(text, label)]\n",
    "\n",
    "def vowel(word):\n",
    "    vowels = {\"a\", \"e\", \"i\", \"o\", \"u\"}\n",
    "    return [(letter, int(letter in vowels)) for letter in word.text]\n",
    "\n",
    "def prefix_and_suffix(word):\n",
    "    word_len = len(word.text)\n",
    "    label = [0] * word_len\n",
    "\n",
    "    for i in range(word_len):\n",
    "        pattern = word.text[:word_len - 1 - i]\n",
    "        if pattern in known_prefixes:\n",
    "            label[len(pattern)] = 1\n",
    "\n",
    "    for i in range(word_len):\n",
    "        pattern = word.text[i + 1:]\n",
    "        if pattern in known_suffixes:\n",
    "            label[i] = 2 if label[i] == 0 else 3\n",
    "\n",
    "    return [t for t in zip(word.text, label)]\n",
    "\n",
    "label_func[EVQR_AFFIX] = evqr_affix\n",
    "label_func[VOWEL] = vowel\n",
    "label_func[PREFIX_AND_SUFFIX] = prefix_and_suffix\n",
    "print('Mapping done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Label for each Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5237/5237 [00:00<00:00, 64802.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for word in tqdm(word_dict.values()):\n",
    "    if not word.create_label(EVQR_AFFIX):\n",
    "        print('Failed at label with EVQR.affix')\n",
    "    if not word.create_label(VOWEL):\n",
    "        print('Failed at label with Vowel')\n",
    "    if not word.create_label(PREFIX_AND_SUFFIX):\n",
    "        print('Failed at label with prefix & suffix')\n",
    "print('Label done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled by EVQR.word.and.suffix: ignoble -> [('i', 0), ('g', 0), ('n', 1), ('o', 0), ('b', 0), ('l', 0), ('e', 0)]\n",
      "labeled by prefix & suffix     : demagog -> [('d', 0), ('e', 0), ('m', 1), ('a', 0), ('g', 0), ('o', 0), ('g', 0)]\n",
      "labeled by position of vowels  : amphibology -> [('a', 1), ('m', 0), ('p', 0), ('h', 0), ('i', 1), ('b', 0), ('o', 1), ('l', 0), ('o', 1), ('g', 0), ('y', 0)]\n"
     ]
    }
   ],
   "source": [
    "print(f'labeled by EVQR.word.and.suffix: ignoble -> {word_dict[\"ignoble\"].label[EVQR_AFFIX]}')\n",
    "print(f'labeled by prefix & suffix     : demagog -> {word_dict[\"demagog\"].label[PREFIX_AND_SUFFIX]}')\n",
    "print(f'labeled by position of vowels  : amphibology -> {word_dict[\"amphibology\"].label[VOWEL]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5237/5237 [00:00<00:00, 1312709.62it/s]\n"
     ]
    }
   ],
   "source": [
    "prepared_word = []\n",
    "for word in tqdm(word_dict.values()):\n",
    "    prepared_word.append(word.label[PREFIX_AND_SUFFIX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training\n",
    "### features creator\n",
    "based on\n",
    "1. prev & after letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_char_features(word, i):\n",
    "    features = [\n",
    "        'bias',\n",
    "        'char=' + word[i][0]\n",
    "    ]\n",
    "\n",
    "    if i >= 1:\n",
    "        features.extend([\n",
    "            'char-1=' + word[i-1][0],\n",
    "            'char-1:0=' + word[i-1][0] + word[i][0],\n",
    "        ])\n",
    "    else:\n",
    "        features.append(\"BOS\")\n",
    "\n",
    "    if i >= 2:\n",
    "        features.extend([\n",
    "            'char-2=' + word[i-2][0],\n",
    "            'char-2:0=' + word[i-2][0] + word[i-1][0] + word[i][0],\n",
    "            'char-2:-1=' + word[i-2][0] + word[i-1][0],\n",
    "        ])\n",
    "    return features\n",
    "\n",
    "\n",
    "def create_word_features(prepared_word):\n",
    "    return [create_char_features(prepared_word, i) for i in range(len(prepared_word))]\n",
    "\n",
    "\n",
    "def create_word_labels(prepared_word):\n",
    "    return [str(part[1]) for part in prepared_word]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### create k-fold cross validation\n",
    "we split all data into 5 folds here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_range = set(range(len(word_dict.values())))\n",
    "sample_set_size = ceil(len(sample_range) / CROSS_VALIDATION_FOLD)\n",
    "sample_list = []\n",
    "selected_samples = set()\n",
    "for i in range(CROSS_VALIDATION_FOLD - 1):\n",
    "    samples = set(sample(sample_range, sample_set_size))\n",
    "    sample_list.append(samples)\n",
    "    sample_range.difference_update(samples)\n",
    "sample_list.append(set(sample_range))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for l in sample_list:\n",
    "    print(' ')\n",
    "    print(list(sorted(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### interface of using pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(folds):\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "    for fold in tqdm(folds):\n",
    "        for idx in fold:\n",
    "            trainer.append(create_word_features(prepared_word[idx]),\n",
    "                           create_word_labels(prepared_word[idx]))\n",
    "\n",
    "    trainer.set_params({\n",
    "        'c1': 1.0,\n",
    "        'c2': 1e-3,\n",
    "        'max_iterations': 50,\n",
    "        'feature.possible_transitions': True\n",
    "    })\n",
    "    trainer.train('word-segmentation.crfsuite')\n",
    "\n",
    "\n",
    "def test(fold):\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open('word-segmentation.crfsuite')\n",
    "    score = 0\n",
    "    for word in fold:\n",
    "        w = word.replace(\" \", \"\")\n",
    "        prediction = tagger.tag(create_word_features(w))\n",
    "        complete = \"\"\n",
    "        for i, p in enumerate(prediction):\n",
    "            if int(p) >= 1:\n",
    "                complete += \" \" + w[i]\n",
    "            else:\n",
    "                complete += w[i]\n",
    "        if complete == ' '.join(word_dict[word].affix_list):\n",
    "            score += 1\n",
    "        else:\n",
    "            print(f'{word} -> {complete}, {word_dict[word].affix_list}')\n",
    "    return score / len(fold)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Implement\n",
    "run 5 times of train & test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_list = list(word_dict.values())\n",
    "scores = []\n",
    "for test_set_idx in range(len(sample_list)):\n",
    "    test_fold = [word_list[idx].text for idx in sample_list[test_set_idx]]\n",
    "    train_folds = sample_list[:test_set_idx] + sample_list[(test_set_idx+1):]\n",
    "    train(train_folds)\n",
    "    scores.append(test(test_fold))\n",
    "print(scores)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}